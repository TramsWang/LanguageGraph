# 2023.01.09 中文词汇依存实验

本实验目的在于观察中文词汇、概念之间是如何组织的，是否存在互相依赖的解释。初步观察构建一个语言概念图谱结构的难度，并且看看是否能从中获取一些构建语言概念网络的灵感。

## 1. 实验流程
### 1.1 获取词典数据
中文词典的数据来源于[汉文学网](https://cd.hwxnet.com/)的拼音检索词典内容，采用[八爪鱼](https://www.bazhuayu.com/)爬取的词条解释。词条内容包含：
1. 词条文本
2. 词条拼音
3. 词条解释

由于在线资源并没有给出词性、词类等信息，本次所用的词条数据相对简单。爬取的词条结果见`datasets/中文词典.7z`文件。该文件中还包含百度的中文停用词表。

原始数据的处理包含两步：
1. 从原始数据中提取词条解释并结构化：这一步的代码参见`util.dictionary.FilterPhraseExplanations.java`
2. 将词条解释分词：这一步使用了[结巴分词](https://github.com/fxsjy/jieba)，通过精确分词模式将解释句拆开为词汇，代码参见`util.dictionary.SplitExplanations.py`

### 1.2 构造依赖图
结构化好的词典数据可以用来构造词汇的依赖图。设依赖图为$\mathcal{G}=\langle V, E \rangle$，其中$V$为出现在词条及其解释中的词汇，若$u, v \in V$，词条$u$的某条解释中包含词汇$v$，则$(u, v) \in E$。依赖图构造好之后，运行Tarjan算法观察强连通分量（SCC），在强连通分量上运行FVS算法观察打破这些SCC的成本。

## 2. 结果
以下是原始输出结果：

> Original Graph: 234121 nodes, 1351013 edges, average degree is 11.54; average explanation cardinality: 12.15
> 
> Finding cycles with stop phrases:
> 
> 1526 SCCs, 7609 nodes involved, at most 3763 FVS needed
> 
> 7079 self loops; 0 unexceptional singleton SCCs
> 
> Original Graph: 234121 nodes, 1095770 edges, average degree is 9.36; average explanation cardinality: 9.86
> 
> Finding cycles without stop phrases:
> 
> 1542 SCCs, 7242 nodes involved, at most 3582 FVS needed
> 
> 7155 self loops; 0 unexceptional singleton SCCs

## 2.1 完整图
词典中有收录的词条数量为11 1188条，加上词条的解释后，图中一共有23 4121个词语（由于解释词条中未去除标点符号，这些词条中包含了一些标点符号），词典收录的比率为47.49%。图中有135 1013条边，节点的平均度数为11.54。仅考虑被收录的词条，每一个词平均需要12.15个词进行解释（包含标点符号）。

Tarjan算法发现图中包含1526个**非单点的**SCC，总共包含7609个节点，打破这些环需要使得至多3763个词汇变成不需要解释的基础词汇。平均一个SCC中包含4.99个词汇，打破这些环路需要转变2.47个词汇。同时，Tarjan算法还发现有7079个词汇的解释涉及到了自己。以下列举了这些词汇的10个随机采样：

```json
[
    {
        "phrase": "小学",
        "pinyin": "xiǎo xué",
        "explanations": [
            ["实施", "初等教育", "的", "学校", "。", "中国", "小学", "入学年龄", "为", "六", "周岁", "，", "学习年限", "为", "六年", "。"]
        ]
    },
    {
        "phrase": "间接",
        "pinyin": "jiàn jiē",
        "explanations": [
            ["经过", "中间", "事物", "发生", "关系", "的", "。", "与", "“", "直接", "”", "相对", "：", "间接", "联络", "｜", "间接", "关系", "。"]
        ]
    },
    {
        "phrase": "繁忙",
        "pinyin": "fán máng",
        "explanations": [
            ["事情", "多", "，", "不得", "空", "：", "工作", "繁忙", "。"]
        ]
    },
    {
        "phrase": "饭颗",
        "pinyin": "fàn kē",
        "explanations": [
            ["指", "饭粒", "。"],
            ["见", "“", "饭颗", "山", "”", "。"]
        ]
    },
    {
        "phrase": "方制",
        "pinyin": "fāng zhì",
        "explanations": [
            ["谓", "方始", "制定", "疆域", "。", "《", "汉书", "．", "地理", "志上", "》", ":", "“", "昔在", "黄帝", "，", "作", "舟车", "以济", "不通", "，", "旁", "行天下", "，", "方制", "万里", "，", "画野", "分州", "，", "得", "百里", "之国", "万区", "。", "”", "颜师古", "注", ":", "“", "方制", "，", "制", "为", "方域", "也", "。", "”", "王先谦", "补注", ":", "“", "《", "广雅", "．", "释诂", "》", ":", "‘", "方", "，", "始", "也", "。", "’", "言", "黄帝", "徧", "行天下", "，", "始", "裁制", "万里", "，", "区别", "州野", "。", "”", "后", "引申", "指", "疆域", "。"]
        ]
    },
    {
        "phrase": "膝盖",
        "pinyin": "xī gài",
        "explanations": [
            ["膝盖", "。"]
        ]
    },
    {
        "phrase": "三戟",
        "pinyin": "sān jǐ",
        "explanations": [
            ["唐制", "，", "三品", "以上", "官员", "得", "门前", "立戟", "。", "李", "岘", "与", "兄", "峘", "﹑", "峄", "同居", "长兴", "里", "第", "，", "门列", "三戟", "。", "张俭", "兄弟", "三人皆立", "戟", "，", "时号", "“", "三戟", "张家", "”", "。", "崔琳", "与", "弟", "珪", "﹑", "瑶", "，", "俱立", "棨", "戟", "，", "世号", "“", "三戟", "崔家", "”", "。", "俱见", "《", "新唐书", "》", "本传", "。", "后", "遂", "以", "“", "三戟", "”", "指贵", "官之家", "。"]
        ]
    },
    {
        "phrase": "单传",
        "pinyin": "dān chuán",
        "explanations": [
            ["一师", "所", "传", "，", "不杂别", "派", "。"],
            ["唯有", "一", "子", "传代", "。"],
            ["佛教", "禅宗", "传法", "，", "不立文字", "，", "见性成佛", "，", "谓之", "单传", "。"]
        ]
    },
    {
        "phrase": "老气横秋",
        "pinyin": "lǎo qì héng qiū",
        "explanations": [
            ["老气", "：", "老年人", "的", "气派", "；", "横", "：", "充满", "。", "形容", "老练", "而", "自负", "的", "神态", "。", "现", "形容", "自高自大", "，", "摆", "老资格", "。", "也", "形容", "缺乏", "朝气", "。"],
            ["∶", "形容", "老练", "而", "自负", "的", "神气"],
            ["东坡", "笔端", "游戏", ",", "槎", "牙", "老气横秋", "。", "—", "—", " ", "宋", "·", " ", "楼钥", "《", "玫槐集", "》"],
            ["∶", "形容", "缺乏", "朝气", ",", "暮气沉沉"],
            ["清", "·", " ", "吴趼人", "《", "二十年", "目睹", "之", "怪现状", "》"]
        ]
    },
    {
        "phrase": "吉鸿昌",
        "pinyin": "jí hóng chāng ",
        "explanations": [
            ["吉鸿昌", "(", "1895", "-", "1934", ")", "河南", "扶沟", "人", "。", "1913", "年入", "冯玉祥", "部", "当兵", "，", "以", "骁勇善战", "升任", "旅", "、", "师长", "。", "1930", "年", "中原", "大", "战后", "接受", "蒋介石", "改编", "，", "任", "国民党", "政府", "第二十二路", "军", "总指挥", "。", "1931", "年", "因", "拒绝", "“", "剿共", "”", "被迫", "出国", "。", "1933", "年", "参与", "组织", "察哈尔", "民众", "抗日", "同盟军", "，", "任", "第二", "军", "军长", "、", "北路", "前敌", "总指挥", "，", "在", "不到", "一个月", "内", "将", "日", "伪军", "驱逐", "出", "察哈尔", "全境", "。", "后", "在", "蒋介石", "军队", "和", "日", "伪军", "夹攻", "下", "失败", "。", "1934", "年", "加入", "中国共产党", "。", "同年", "11", "月", "在", "北平", "被", "杀害", "。"]
        ]
    },
]
```

通过随机采样的10个这样的词汇，可以发现有8个并非对词汇本身的解释。其中：
- 出现在相关拓展信息中的有：小学，饭颗，方制，三戟，老气横秋，吉鸿昌
- 出现在例子中的有：间接，繁忙
- 没有对自身的有效解释的有：膝盖

只有2个是作为解释语句的主体或客体出现，使之形成完整语句：单传，吉鸿昌。

## 2.2 去除解释中包含的停用词
接下来，我去除了解释中包含的停用词，并重新运行上述流程。此时，图中还剩下109 5770条边，节点的平均度数为9.36。仅考虑被收录的词条，每一个词平均需要9.86个词进行解释。也就是说，平均一个词条解释中会包含2.29个停用词。

Tarjan算法发现图中包含1542个**非单点的**SCC，总共包含7242个节点，打破这些环需要使得至多3582个词汇变成不需要解释的基础词汇。平均一个SCC中包含4.70个词汇，打破这些环路需要转变2.32个词汇。同时，Tarjan算法还发现有7155个词汇的解释涉及到了自己。SCC数量增多但是包含的节点数量变少表明有一些停用词被包含在了一些环路中。

## 3. 讨论

### 3.1 数据质量（定义句式/语义的判定）
从上面列举的例子可以看出，目前采集的数据虽然经过了一些格式化处理，去掉了很多例句等与定义无关的内容，但是仍然还留有很多无关的噪音数据。这个问题从另一个角度看就是对语句的语义判定的问题。例如，在这个实验中，我希望只保留对词汇的语义的解释和定义，舍弃其他内容，这就需要判定一个语句是否是对某个概念的定义。尤其是在一些特定的文本结构中（比如词典），文本的组织结构本身就包含一定的对语义的约束（词典中的定义一般出现在第一句，并且会省略定义的主体）。

### 3.2 定义的基础
类比数学的定义和证明都需要有一些前提，对自然语义的定义也必须建立在一些公理基础之上。再对定义的过程赋予某种顺序约束，才能使得最终得到的图成为一个有向无环图（DAG）。

那么这些基础是什么呢？早在去年和Daniel讨论这样的设想的时候，我就已经有了初步的构想：这些基础只能源于人类和物质世界交互的接口——人类的物质基础，即感官。我们通过眼睛辨识颜色，接受云朵是白色的，这并不需要什么定义或推理，这就是定义本身，是公理。我们感受到快乐抑或愤怒，这些感觉并非通过理性思考得到，它们就是定义本身，是公理。

类似地，在规定自然语义图的基础节点的时候，我们可以参考人类的感官基础，也可以根据可以给机器赋予的所有“感官”的基础进行更强大的设计。这个问题是今后研究需要明确的基础问题之一。应当先从人类本身具备的感官开始，逐步拓展试验到将现代科学仪器设备都纳入版图的广大范围。

### 3.3 自然语义图的定位
在进行上述讨论时，有一个默认的前提，即：自然语义图的内容是对人类可以理解的概念进行定义的一张大图。这个约定还十分模糊。我们应当对其具体的结构进行足够精细的刻画，才能明确具体的研究内容和路线。

从语言上看，这张图应该包含对语言能够表达的概念的定义。因为定义是清晰的、明确的、符合逻辑的，所以这些定义应当基于逻辑的形式表达。【注1】并且，这些定义应该能够适应自然语言多义性的特点，区别这些用相同符号表达的不同含义。

从定义的范围上看，语义的定义应该是概念而非个体。也就是说，自然语义图关注的是共性的属性、类别、关系等内容，具体的事物不在其表达范围之内，或者至少可以区分，并用别的方式表达。个体的内容可以通过某种方式同与其相关的共性概念相联系。

Daniel的设想从知识图谱的概念出发，每个实体和关系都应当具有定义。例如，“云”的定义是“漂浮在空中的，形状不规则的，白色的物体”，而“X漂浮在Y中”这个关系可以进一步定义为“X的位置始终在Y的边界范围之内”。

根据上述的三个描述，我们可以大致说出自然语义图的结构：
- 逻辑化：自然语义图是通过图结构表达逻辑关系的一种形式，即其与逻辑表达式可以互相转化。因此，自然语义图也可以看做是一个巨大的逻辑程序，其逻辑形式为高阶逻辑，可以包含递归、类型系统等便于表达的语法特性【注2】。由3.2节所言，这种定义中包含一套公理系统。

- 多义与多重定义：自然语义图中的语义和符号是解耦的，于是可以体现自然语言的歧义性。语义通过符号的连接和组合方式表达，通过符号命名。因此多义性体现于组合体和具体的命名符号的多对一的关系。从另一个方面讲，不同的人对于同一个概念会有不同的定义，接受何种定义、如何融合不同的定义也是后续需要解决的问题。
- 应用：语义图的应用在于图结构和自然语言之间的相互对应关系。图结构可以转化为自然语言输出，使其具有表达自身的能力；自然语言可以通过解析转化为图结构，使其可以理解外部交互。前者可以通过多样化的语法、语言习惯的配置使其的表达能力接近于人类，后者可以通过对上下文和不同语言环境的建模与匹配使其理解能力接近于人类。
- 任务化：图结构与自然语言之间的相互转化是对自然语义图的应用的最基础任务。我们应当认为，所有的对语言的使用都伴随着某种任务的触发【注3】，如对图的查询和修改，甚至于对于这些任务本身流程的定义和修改。这其实暗示着对语义的解释和使用可以和自动化编程结合在一起，我们所需的只是定义一套语义和基础计算过程互相转化的公理系统，正如语义和自然语言那样。这就包含了自学习的能力，通过适当的引导，可以实现语义图的（半）自主更新。于是，如何定义这些任务，如何定义原子任务和复合任务，这些都是需要考虑的问题。
- 定义非逻辑化

> 【注1】我并不否认在当前的广袤的语言空间里包含一些所谓“只可意会不可言传”的不能定义的内容。但是作为研究的第一步，必须只能考虑那些能够定义的，只有将这些能够定义的内容表达清楚，我们才能明确哪些内容是无法表达清楚、无法定义的。
>
> 【注2】需要说明的一点是，相比于可计算性，自然语义图应当更注重可表达性。计算复杂性往往约束了逻辑形式的表达能力，从而使其应用受限。这个研究项目希望能够用一种白盒的方式解构自然语言，必须使其能够具有和自然语言一样的表达性。人类的知识世界中已然包含了很多被证明无法解决或无法有效解决的问题，但这并不妨碍人类文明继续向前发展。我对这个项目也秉持同样的态度。
>
> 但是，Daniel认为逻辑的形式应当约束在一阶逻辑的范围内，因为人类的语言本身是非递归的。对这个问题我的理解是：自然语言的表达（即语法）是一阶的、非递归的，但是其表达的含义转换成逻辑形式后却对应的是高阶逻辑。例如对“互相”的定义：
> > 副词。表示彼此同样对待的关系
>
> 用逻辑表示的话应该是这样的：
> > $互相(\alpha) \equiv \forall x,y, \alpha(x,y) \implies \alpha(y,x)$
>
> 转述成自然语言就是：一个关系是互相的表示主语对宾语有这个关系同时宾语对主语也有这个关系。
>
> 【注3】对于这一论点目前并没有很好的论证。我目前倾向于认为所有的语言表达都服从于某一种特定的目的，比如询问、命令、通知等。而当人们无法确认一句话的意图时，默认的意图应当是“通知”，仅仅是将一个系统的语义传递到另一个系统的这样的一个任务。

### 3.4 数据的来源

根据语义图的定位，在项目初期应该聚焦于逻辑化的定义的内容，因此数据的收集应该以此为导向，着重关注包含定义类型的文本数据，并能够转化为标准的语句格式。词典、百科、甚至问答数据都可以考虑在内。注意区分概念定义和从属定义。

### ※ 3.5 逻辑和概率的结合

这部分属于一些“遐想”。从我目前正在进行的Rule Mining相关项目的经验来看，逻辑与概率的结合点除了在于可以将概率模糊化以外，还在于概率对逻辑推理的搜索启发。虽然高阶逻辑的判定问题是难的甚至不可解的，但是我们仍然可以通过启发的方式“碰运气”，或者近似。当语义图的规模足够庞大的时候，它理论上能支撑人类当前所掌握的所有推理任务，只是计算量无法承受。此时使其习得一些启发模式，则可以近似解决一些问题或者碰巧发现解。这可能是将来强AI的一种发展方向。

## 4. 下一步工作内容

这里对项目的发展路径做一个初步的规划。

1. 构建小规模语义图
   1. 明确定义基础
   2. 实现图结构与文本的互相转化
   3. 解决多义、多重定义问题
   4. 应用：机器翻译
2. 构建大规模语义图
   1. 迭代使用小规模语义图理解更多自然语言文本，扩展、更新语义图；在必要时引入人的因素干预
   2. 除了概念定义的内容，再引入个体与概念之间的从属关系，从而结合现在的知识图谱概念，构建包含定义与从属两个层面知识的大型知识库
   3. 应用：理解自然语义的可交互的搜索引擎，具有上下文意识的对话机器人
3. 语义图的任务化
   1. 明确原子任务与复合任务
   2. 确定语义与任务的互相转化关系
   3. 实现“自然语言$\rightarrow$语义图$\rightarrow$程序”的自动程序编写功能
   4. 应用：可培养的智能体